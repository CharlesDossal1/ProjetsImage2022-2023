{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, several algorithms are tested to perform deconvolution, that is to remove or decrease a blur on an image. This blur may come from the optical system (lens or atmopheric perturbations), from diffraction effect (electronic microscopy) from the the move of the camera. If we consider that the blur is uniform we can assert that it exists a filter $h$ such that \n",
    "\\begin{equation}\n",
    "y=h\\star x^0 +n\n",
    "\\end{equation}\n",
    "where $x^0$ is the image to recover or estimate, $n$ a noise and $y$ are the observations.\n",
    "\n",
    "in the following, we will suppose that $h$ is a gaussian kernel, but the analysis applies to any kernel. We will also suppose that the noise $n$ is a the realisation of a random gaussian variable $N$ with zero mean a covariance matrix $\\sigma^2 Id$ proportional to $Id$ (a with gaussian noise). This hypothis is quite crucial in the following analysis. \n",
    "To consider more general noise, the functions we are minimizing should be modified accordingly.\n",
    "\n",
    "We will also suppose that the kernel $h$ and the noise intensity $\\sigma^2$ is known. In practical cases, $h$ and $\\sigma^2$ may be estimated in a first step. \n",
    "\n",
    "We will consider several scenario : 2 images (or more), 3 kernels and 6 noise intensities. On each of these 36 situations we will try to find the best method for the deconvolution.\n",
    "\n",
    "Each method depends on at least one parameter, sometimes more. To compare them as fairly as possible, we will try to find the best set of parameters of each of them. we will consider that the set of paramter this is the best is the one maximizing the PSNR with the reference image. In pratice, it is not known... but to evaluate each method we will assume we have it.   \n",
    "\n",
    "The fisrt method we will consider is the Wiener filtering. The wiener filtering consists in minimizing the following function $F$\n",
    "\\begin{equation}\\label{Wiener}\n",
    "F(x)=\\frac{1}{2}||h\\star x-y||_2^2+\\frac{\\lambda}{2}||x||_2^2 \n",
    "\\end{equation}\n",
    "This minimizer $\\hat x$ of $F$ as a close form : its discrete Fourier transform is defined by \n",
    "\\begin{equation}\n",
    "\\hat x(\\omega)=\\hat y(\\omega)\\frac{\\overline{\\hat h(\\omega)}}{|\\hat h(\\omega)|^2+\\lambda}\n",
    "\\end{equation}\n",
    "In the first part of the notebook, we will implement this method and try to find the optimal value of $\\lambda$ that may depends on the kernel $h$, on the noise intensity $\\sigma^2$, the size and the dynamic of the image. \n",
    "\n",
    "To estimate the best parameter $\\lambda$ we use the following procedure.\n",
    "\n",
    "- We fix the image, the kernel $h$, the noise intensity and a large set of parameters $\\lambda$.\n",
    "- We display the PSNR of the reconstruction as a function of $\\lambda$ and find the optimal $\\lambda$. We have to try several sets of values of $\\lambda$ to find the best one with a raisonnable accuracy.\n",
    "- Then we change sequentially the image, the kernel $h$ and the noise intensity (one at a time) to have an idea of the dependency of the optimal parameter with respect to $h$, $\\sigma^2$ of the image (or the size of the image).\n",
    "For example, we should observe that the optimal parameter is roughly proportional to the standart deviation of the noise.\n",
    "- Once these dependencies have been estimated, for each case (image, noise intensity, kernel h) we are able to have a reasonnable range of $\\lambda$. We thus try several values of $\\lambda$ close to this first estimation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In a second part we will estimate $x^0$ minimizing a function $F$ :\n",
    "\\begin{equation}\\label{OthoWave}\n",
    "F(x)=\\frac{1}{2}||h\\star x-y||_2^2+\\lambda||Wx||_1 \n",
    "\\end{equation}\n",
    "where $W$ is an orthognal wavelet transform. This variational formmulation will be relevant if the wavelet coefficients of target image $x^0$ are sparse. The choice of the optimal $\\lambda$ depends on the kernel $h$ and on the noise intensity $\\sigma^2$ and the choice of the optimal wavelet depends on the image. \n",
    "\n",
    "We will use FISTA with $\\alpha=3$ to solve this optimization problem and use the result of the optimal Wiener deconvolution as a starting point. \n",
    "\n",
    "The optimal value of $\\lambda$ may be estimated as previously. We may observe that the number iterations necessary to get a good result may be quite small (less than 300) since FISTA is fast and since the starting point is a good first guess of th solution. We may also observe that the optimal value of $\\lambda$ doesn't really depends on the choice of the chosen wavelet basis.   \n",
    "\n",
    "In a third part, we will estimate $x^0$ minimizing a function $F$ :\n",
    "\\begin{equation}\\label{TIWave}\n",
    "F(x)=\\frac{1}{2}||h\\star x-y||_2^2+\\lambda||W_{TI}x||_1 \n",
    "\\end{equation}\n",
    "where $W_{TI}$ is a translation invariant wavelet transform. This transformation (with suitable options) is a tight frame, that is $W_{TI}^*W_{TI}=Id$ even if  $W_{TI}W_{TI}^*\\neq Id$. This property implies that the the proximity operator of $g(x)=||W_{TI}x||_1 $ is a soft thresholding of the wavelet coefficients :\n",
    "\\begin{equation}\\label{prox_wti}\n",
    "prox_{||W_{TI}\\cdot||_1}(x)=W_{TI}^*\\circ\\text{SoftThresh}\\circ W_{TI}(x).\n",
    "\\end{equation}\n",
    "\n",
    "Be careful : the optimal value of $\\lambda$ is different than the optimal one for the orthogonal transform.\n",
    "\n",
    "This function \\eqref{TIWave} may be minimized using FISTA or Douglas Rachford using a smart starting point.  \n",
    "In this part we will compare both algorithms. \n",
    "\n",
    "In the fourth and last part, \n",
    "we will estimate $x^0$ minimizing a function $F$ :\n",
    "\\begin{equation}\\label{deconv_TV}\n",
    "F(x)=\\frac{1}{2}||h\\star x-y||_2^2+\\lambda||\\nabla x||_1 \n",
    "\\end{equation}\n",
    "Using the Chambolle-Pock Algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "import pywt\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import param\n",
    "import panel as pn\n",
    "from panel.pane import LaTeX\n",
    "hv.extension('bokeh')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import time\n",
    "import itertools\n",
    "import hvplot.pandas\n",
    "from bokeh.models import HoverTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local=0\n",
    "def chargeData(name):\n",
    "    if local:\n",
    "        if name=='Lenna':\n",
    "            res=np.array(Image.open(\"./Archive/img/Lenna.jpg\")).astype(float)\n",
    "        if name=='Canaletto':\n",
    "            res=np.array(Image.open(\"./Archive/img/Canaletto.jpeg\")).astype(float)\n",
    "        if name=='Minotaure':\n",
    "            res=np.array(Image.open(\"./Archive/img/MinotaureBruite.jpeg\")).astype(float)   \n",
    "        if name=='Cartoon':\n",
    "            res=np.array(Image.open(\"./Archive/img/Cartoon.jpg\")).astype(float) \n",
    "    else:\n",
    "        if name=='Lenna':\n",
    "            url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/Lenna.jpg'        \n",
    "            response = requests.get(url)\n",
    "            res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "        if name=='Canaletto':\n",
    "            url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/Canaletto.jpeg'\n",
    "            response = requests.get(url)\n",
    "            res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "        if name=='Minotaure':\n",
    "            url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/MinotaureBruite.jpeg'\n",
    "            response = requests.get(url)\n",
    "            res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "        if name=='Cartoon':\n",
    "            url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/Cartoon.jpg'        \n",
    "            response = requests.get(url)\n",
    "            res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=chargeData('Canaletto')\n",
    "im2=chargeData('Lenna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blocks2,Piece,im,im2,Mi=np.load('dataTP.npy',allow_pickle=True)\n",
    "imagesRef= {\"Lenna\" : im2,\"Canaletto\" : im}\n",
    "options = dict(cmap='gray',xaxis=None,yaxis=None,width=450,height=450,toolbar=None)\n",
    "pn.Row(hv.Raster(imagesRef[\"Lenna\"]).opts(**options),hv.Raster(imagesRef[\"Canaletto\"]).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction PSNR calcule le PSNR\n",
    "def PSNR(I,Iref):\n",
    "    temp=I.ravel()\n",
    "    tempref=Iref.ravel()\n",
    "    NbP=I.size\n",
    "    EQM=np.sum((temp-tempref)**2)/NbP\n",
    "    b=np.max(np.abs(tempref))**2\n",
    "    return 10*np.log10(b/EQM)\n",
    "\n",
    "# fonction Gaussian2D N = taille image, sigma = intensité du filtre => créer h kernel gaussien  \n",
    "def Gaussian2D(N,sigma):\n",
    "    x, y = np.meshgrid(np.linspace(-1,1,N), np.linspace(-1,1,N))\n",
    "    d = np.sqrt(x*x+y*y)\n",
    "    mu =0.0\n",
    "    g= np.exp(-( (d-mu)**2 / ( 2.0 * sigma**2 ) ) )\n",
    "    g2=np.fft.fftshift(g)\n",
    "    s=sum(sum(g2))\n",
    "    g2=g2/s\n",
    "    return g2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Wiener Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first generate the blured data $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#générer trois kernel gaussiens \n",
    "h_1=Gaussian2D(512,0.005)\n",
    "h_2=Gaussian2D(512,0.01)\n",
    "h_3=Gaussian2D(512,0.02)\n",
    "blur= {\"low\" : 0.005,\"medium\":0.01,\"high\":0.02}\n",
    "\n",
    "# image flouttée y = h*x+n\n",
    "im=imagesRef[\"Canaletto\"]\n",
    "h=h_2\n",
    "fh=np.fft.fft2(h)  # Compute the 2-dimensional discrete Fourier Transform\n",
    "noise_std=5 #intensité du bruit\n",
    "imconv=np.real(np.fft.ifft2(np.fft.fft2(im)*fh))+noise_std*np.random.randn(512,512) \n",
    "# np.random.randn = Return a sample (or samples) from the “standard normal” distribution\n",
    "print(PSNR(imconv,im))\n",
    "\n",
    "pn.Row(hv.Image(im,label='Image originale').opts(**options),hv.Image(imconv, label='Image bruitée kernel 2').opts(**options) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the Wiener filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiener(imconv,fh,lam):\n",
    "    ffti=np.fft.fft2(imconv) #transformée de fourier de l'image bruitée\n",
    "    fftw=np.conj(fh)/(lam+np.abs(fh)**2) # conjuguée du filtre/(|filtre|+lambda)\n",
    "    return np.real(np.fft.ifft2(ffti*fftw)) #transfo de fourier minimiseur x = transfo de fourier de (ffti * conjuguée du filtre/(|filtre|+lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An try it for a $\\lambda=0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xwiener=wiener(imconv,fh,0.01)\n",
    "print('PSNR = ', PSNR(xwiener,im))\n",
    "pn.Row(hv.Image(im,label='Image originale').opts(**options), hv.Image(imconv,label='Image bruitée').opts(**options), hv.Image(xwiener, label = 'Deconvolution de Wiener').opts(**options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function computes the Wiener deconvolution for a set of paramters contains in a vector lamvec. Outputs are f, the values of the associated PSNR, m the maximum of the PSNR over the set of tested parameters and lamop the best value of $\\lambda$ in the vector lamvec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testwiener(imconv,fh,ref,lamvec):\n",
    "    f=[]\n",
    "    for lam in lamvec:\n",
    "        p=PSNR(wiener(imconv,fh,lam),ref)\n",
    "        f.append(p)\n",
    "    m=np.max(f)\n",
    "    k=np.argmax(f)\n",
    "    lamop=lamvec[k]\n",
    "    return f,m,lamop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the function for $\\lambda\\in[10^{-3},\\,\\, 2\\times 10^{-2}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamvec=np.linspace(0.001,0.02, num=100)\n",
    "f,m,l=testwiener(imconv,fh,im,lamvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dashbord to display the result of the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deconv_wiener(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Lenna\",objects=imagesRef.keys())\n",
    "    std_filter = param.ObjectSelector(default=\"medium\",objects=blur.keys())\n",
    "    std_noise= param.Number(10,bounds=(1,30))\n",
    "    loglam = param.Number(-3,bounds=(-5,4))\n",
    "    def view(self):\n",
    "        nblambda=1000\n",
    "        lam=10**self.loglam\n",
    "        imtemp=imagesRef[self.image]\n",
    "        np.random.seed(seed=1)\n",
    "        n1,n2=np.shape(imtemp)\n",
    "        noise=np.random.randn(n1,n2)\n",
    "        h=Gaussian2D(n1,blur[self.std_filter])\n",
    "        fh=np.fft.fft2(h)\n",
    "        imconv=np.real(np.fft.ifft2(np.fft.fft2(imtemp)*fh))+self.std_noise*noise\n",
    "        lamvec=np.linspace(lam,100*lam, num=nblambda)\n",
    "        f,m,lamop=testwiener(imconv,fh,imtemp,lamvec)\n",
    "        inf_lam=np.min(f)\n",
    "        im_rec=wiener(imconv,fh,lamop)\n",
    "        p1=PSNR(imconv,imtemp)\n",
    "        p2=PSNR(im_rec,imtemp)\n",
    "        strp1=\"%2.2f\" % p1\n",
    "        strp2=\"%2.2f\" % p2\n",
    "        strlam=\"%2.3f\"% lamop\n",
    "        #lames=3*self.std_noise/(blur[self.std_filter]*n1**2)\n",
    "        #strlames=\"%2.3f\"% lames\n",
    "        text1=hv.Text(nblambda/2,(m+inf_lam)/2,'PSNR Blured '+strp1)\n",
    "        text2=hv.Text(nblambda/2,0.3*m+0.7*inf_lam,'PSNR Deblured '+strp2)\n",
    "        text3=hv.Text(nblambda/2,0.1*m+0.9*inf_lam,'Optimal lambda '+strlam)#+' et '+strlames)\n",
    "        fig=hv.Curve(f)*text1*text2*text3\n",
    "        options_w = dict(cmap='gray',xaxis=None,yaxis=None,width=300,height=300,toolbar=None)\n",
    "        return pn.Column(pn.Row(hv.Image(imtemp).opts(**options_w)\\\n",
    "                      ,hv.Image(imconv).opts(**options_w)),\\\n",
    "                         pn.Row(hv.Image(im_rec).opts(**options_w),fig.opts(xaxis=None,toolbar=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv_wi= deconv_wiener()\n",
    "pn.Row(deconv_wi.param,deconv_wi.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this dashboard, looking the dependency on each parameter, we observe that the optimal $\\lambda$ is roughly proportional to the noise intensity, proportional to the inverse of the width of the kernel and proportional to the inverse of the number of pixel of the image. We propose an oracle on $\\lambda$ :\n",
    "\\begin{equation}\\label{lamoracle}\n",
    "\\lambda_{oracle}=\\frac{stdnoise}{stdfilter\\times nbpixels}\n",
    "\\end{equation}\n",
    "where stdnoise is the standart deviation of noise and stdfilter the standart deviation of the kernel $h$.\n",
    "\n",
    "This $\\lambda_{oracle}$ is not supposed to be the best one but it seems reasonnable to look for the best one in the intervalle $[\\frac{1}{4}\\lambda_{oracle},25\\lambda_{oracle}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a design of experiments (DOE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = {'image':imagesRef.keys(),'std_filter':blur.keys(),'std_noise':np.linspace(2,22,6)}\n",
    "dfexp = pd.DataFrame(list(itertools.product(*experiences.values())),columns=experiences.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Design of experiments :')\n",
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each set of parameters, we look for the optimal value of $\\lambda$ using the oracle \\eqref{lamoracle}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2PSNR(row):\n",
    "    im=imagesRef[row.image]\n",
    "    n1,n2=np.shape(im)\n",
    "    h=Gaussian2D(n1,blur[row.std_filter])\n",
    "    fh=np.fft.fft2(h)\n",
    "    noise=np.random.randn(n1,n2)\n",
    "    imconv=np.real(np.fft.ifft2(np.fft.fft2(im)*fh))+row.std_noise*noise\n",
    "    lam1=row.std_noise/(4*blur[row.std_filter]*n1**2)\n",
    "    lamvec=np.linspace(lam1,100*lam1,200)\n",
    "    f,p,lamop=testwiener(imconv,fh,im,lamvec)\n",
    "    return {'PSNR':p,'Lambdaop':lamop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowtest=  dfexp.iloc[10]\n",
    "print(rowtest)\n",
    "result_test = row2PSNR(rowtest)\n",
    "print(result_test)\n",
    "result = dfexp.apply(row2PSNR,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp[['LambdaopWiener','PSNRWiener']] = pd.DataFrame.from_records(result.values)\n",
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = HoverTool()\n",
    "dfexp.hvplot('std_noise','LambdaopWiener',kind='scatter',by=['std_filter'],groupby=['image'])\\\n",
    ".opts(width=600,tools = [h]).redim.range(LambdaopWiener=(0.001,0.18),std_noise=(1,23))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function performs the optimal Wiener deconvolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiener_op(imconv,fh,im,std_noise,std_filter):\n",
    "    n1,n2=np.shape(im)\n",
    "    lam1=std_noise/(4*std_filter*n1**2)\n",
    "    lamvec=np.linspace(lam1,100*lam1,200)\n",
    "    f,p,lamop=testwiener(imconv,fh,im,lamvec)\n",
    "    x=wiener(imconv,fh,lamop)\n",
    "    return x,lamop,p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Deconvolution using Wavelet orthogonal basis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to solve the following optimization problem \n",
    "\\begin{equation}\\label{fonc_ond_ortho}\n",
    "\\underset{x}{\\min}\\frac{1}{2}||h\\star x-y||_2^2+\\lambda||Wx||_1\n",
    "\\end{equation}\n",
    "where $W$ is an orthogonal wavelet transform using Forward-Backward or FISTA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the gradient of the function $f(x)=\\frac{1}{2}||h\\star x-y||_2^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradfilter(x,y,fh):\n",
    "    fftx=np.fft.fft2(x)\n",
    "    ffty=np.fft.fft2(y)\n",
    "    fftg=np.conj(fh)*(fftx*fh-ffty)\n",
    "    g=np.real(np.fft.ifft2(fftg))\n",
    "    return g\n",
    "\n",
    "def foncconv(x,b,fh):\n",
    "    fftx=np.fft.fft2(x)\n",
    "    temp=np.fft.ifft2(fftx*fh)-b\n",
    "    no=np.linalg.norm(temp,'fro')\n",
    "    res=0.5*no**2\n",
    "    return res\n",
    "def proxfilter(x,b,fh,gamma):\n",
    "    fftx=np.fft.fft2(x)\n",
    "    fftb=np.fft.fft2(b)\n",
    "    temp=fftx+gamma*np.conj(fh)*fftb\n",
    "    fftp=temp/(1+gamma*np.abs(fh*fh))\n",
    "    p=np.real(np.fft.ifft2(fftp))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the proximity operator of $g(x)=\\lambda ||Wx||_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeuillageDouxOndelettes(I,wave,Seuil):\n",
    "    L=pywt.dwt_max_level(len(I),pywt.Wavelet(wave).dec_len)\n",
    "    wavelet_coeffs= pywt.wavedecn(I, wave, mode='per', level=L)\n",
    "    arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(wavelet_coeffs)\n",
    "    temp=pywt.threshold(arr,Seuil,mode='soft')\n",
    "    test=pywt.unravel_coeffs(temp, coeff_slices, coeff_shapes, output_format='wavedecn')\n",
    "    Irec=pywt.waverecn(test, wave,mode='per')\n",
    "    return Irec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the FB and the FISTA ns the Douglas Raford algorithm. These functions return the last iterate $x$ built by the algorithm and the whole sequence $(F(x_n))_{n\\leqslant nbiter}$ in the variable $f$. You may use a variable fast when you don't want to compute the sequence $(F(x_n))_{n\\leqslant nbiter}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue \">\n",
    "Si $F=f+g$ est une fonction convexe composite, somme de deux fonctions convexes, $f$ différentiable à gradient \n",
    "$L$-Lipschitz et $g$ une fonction convexe dont on sait calculer l'opérateur proximal, l'algorithme Forward-Backward s'écrit \n",
    "$$x_{n+1}=prox_{hg}(x_n-step\\nabla f(x_n))=Tx_n\\quad \\text{ avec }T:=prox_{hg}\\circ (Id-step\\nabla f)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FB_deconv_ond_ortho(imconv,h,wave,step,lam,nbiter,x_init):\n",
    "    Lmax=pywt.dwt_max_level(np.shape(imconv)[1],pywt.Wavelet(wave).dec_len)\n",
    "    fh=np.fft.fft2(h)\n",
    "    f=np.zeros(nbiter)\n",
    "    thresh=step*lam\n",
    "    x=x_init\n",
    "    for k in range(0,nbiter):\n",
    "        grad = gradfilter(x, imconv, fh)\n",
    "        x = SeuillageDouxOndelettes(x-step*grad, wave, thresh)\n",
    "        temp= pywt.wavedecn(x,wave, mode='per', level=Lmax)\n",
    "        arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(temp)\n",
    "        f[k] = foncconv(x, imconv, fh)+lam*sum(np.abs(arr))\n",
    "    x=np.clip(x,0,255)\n",
    "    return x,f  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue \">\n",
    "Il suffit d'effectuer la descente de gradient en un point décalé de $x_n$ avec un pas $h<\\frac{1}{L}$ (attention cette borne est plus contraignante que pour la descente de gradient classique) :\n",
    "$$x_{n+1}=T(x_n+\\alpha_n(x_n-x_{n-1}))$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FISTA_deconv_ond_ortho(imconv,h,wave,step,lam,nbiter,x_init,fast=0): \n",
    "    #Attention avec FISTA step<1/L, prendre un step petit ! \n",
    "    alpha=3\n",
    "    Lmax=pywt.dwt_max_level(np.shape(imconv)[1],pywt.Wavelet(wave).dec_len)\n",
    "    fh=np.fft.fft2(h)\n",
    "    f=np.zeros(nbiter)\n",
    "    thresh=step*lam\n",
    "    x=x_init\n",
    "    x_old=x\n",
    "    for k in range(0,nbiter):\n",
    "        temp1 = x+(k/(k+alpha))*(x-x_old)\n",
    "        grad = gradfilter(temp1, imconv, fh)\n",
    "        x_old = x\n",
    "        x = SeuillageDouxOndelettes(temp1-step*grad, wave, thresh)\n",
    "        if fast<1:\n",
    "            temp = pywt.wavedecn(x,wave, mode='per', level=Lmax)\n",
    "            arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(temp)\n",
    "            f[k]=foncconv(x,imconv,fh)+lam*sum(np.abs(arr))\n",
    "    x=np.clip(x,0,255)\n",
    "    return x,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DouglasRachford_ortho(imconv,h,wave,lam,gamma,rho,niter,x_init):\n",
    "    fh=np.fft.fft2(h)\n",
    "    f=np.zeros(niter)\n",
    "    Lmax=pywt.dwt_max_level(np.shape(imconv)[1],pywt.Wavelet(wave).dec_len)\n",
    "    init=imconv\n",
    "    # initialisation de x,y,z sûrement fausse\n",
    "    #x = x_init\n",
    "    #z= x_init\n",
    "    #y=imconv\n",
    "    #########################################\n",
    "\n",
    "    init=imconv\n",
    "    z=x_init\n",
    "    y=x_init\n",
    "    x=x_init #init.copy\n",
    "    \n",
    "    for k in range(0,niter):\n",
    "        y = gradfilter(x,imconv,fh)\n",
    "        z = proxfilter(2*y-x,imconv,fh,gamma)\n",
    "        x = x + rho*(z-y)\n",
    "        #x = x + 2*(1-lam)*(z-y)\n",
    "        temp = pywt.wavedecn(x,wave, mode='per', level=Lmax)\n",
    "        arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(temp)\n",
    "        f[k]=foncconv(x,imconv,fh)+lam*sum(np.abs(arr))\n",
    "    x = np.clip(x,0,255)\n",
    "    return x,f "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test these functions using Wiener deconvolution for initialisation. With the command time you can estimate the time of each programm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=imagesRef[\"Lenna\"]\n",
    "n1,n2=np.shape(im)\n",
    "h=Gaussian2D(n1,blur[\"medium\"])\n",
    "fh=np.fft.fft2(h)\n",
    "noise=np.random.randn(n1,n2)\n",
    "std_noise=10\n",
    "imconv=np.real(np.fft.ifft2(np.fft.fft2(im)*fh))+std_noise*noise\n",
    "lam=7\n",
    "step=0.08\n",
    "nbiter=500\n",
    "wave='db2'\n",
    "x_init,p,lamop=wiener_op(imconv,fh,im,std_noise,blur[\"medium\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma=1\n",
    "rho=0.001\n",
    "print('PSNR image bruitée :', PSNR(imconv,im))\n",
    "print('PSNR image initialisation (Wiener optimal) :', PSNR(x_init,im))\n",
    "x_dr, f_dr = DouglasRachford_ortho(imconv,h,wave,lam,gamma,rho,nbiter,x_init)\n",
    "print('PSNR débruitage Douglas Rashford :', PSNR(x_dr,im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare Wiener and orthogonal wavelet deconvolution for a reasonnable (but surely not optimal) value of $\\lambda$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 5\n",
    "options1= dict(cmap='gray',xaxis=None,yaxis=None,width=300,height=300,toolbar=None)\n",
    "print('PSNR image bruitée :', PSNR(imconv,im))\n",
    "print('PSNR image initialisation (Wiener optimal) :', PSNR(x_init,im))\n",
    "x_fb, f_fb = FB_deconv_ond_ortho(imconv,h,wave,step,lam,nbiter,x_init)\n",
    "print('PSNR débruitage Forward-Backward :', PSNR(x_fb,im))\n",
    "x_fista, f_fista = FISTA_deconv_ond_ortho(imconv,h,wave,step,lam,nbiter,x_init,fast=0)\n",
    "print('PSNR débruitage FISTA :',PSNR(x_fista,im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve(f_fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve(f_fista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve(f_dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pn.Column(pn.Row(hv.Image(imconv, label='Image bruitée').opts(**options), hv.Image(x_init, label='Image Déconvolution Wiener optimale').opts(**options)), pn.Row(hv.Image(x_fb, label='Image débruitée Forward-Backward').opts(**options), hv.Image(x_fista, label='Image débruitée FISTA').opts(**options)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_param_opti():\n",
    "    psnr = 0.0\n",
    "    lambda_test = [0.01, 0.1, 0.5, 1, 2, 3, 4, 5, 6, 7]\n",
    "    nbiter = 500\n",
    "    lambda_opti = 0\n",
    "    for i in lambda_test:\n",
    "        x_fb, f_fb = FB_deconv_ond_ortho(imconv,h,wave,step,i,nbiter,x_init)\n",
    "        if PSNR(x_dr,im2)>psnr:\n",
    "            psnr=PSNR(x_fb,imconv)\n",
    "            lambda_opti=i\n",
    "        print(\"lambda_test : \" + str(i))\n",
    "    return lambda_opti,psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_test,psnr = Test_param_opti()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fb, f_fb = FB_deconv_ond_ortho(imconv,h,wave,step,lambda_test,nbiter,x_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(hv.Image(imconv, label = 'Image bruitée').opts(**options),hv.Image(x_fb, label = 'Image débruitée FB, meilleur paramètre').opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lambda_test,psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Column(pn.Row(hv.Image(imconv, label='Image bruitée').opts(**options), hv.Image(x_fb, label='Image débruitée Forward-Backward').opts(**options)), pn.Row(hv.Image(x_fista, label='Image débruitée FISTA').opts(**options), hv.Image(x_dr, label='Image débruitée Douglas Rashford').opts(**options)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_param_opti():\n",
    "    psnr = 0.0\n",
    "    lambda_test = [0.01, 0.1, 0.5, 1, 2, 3, 4, 5, 6, 7]\n",
    "    nbiter = 500\n",
    "    lambda_opti = 0\n",
    "    for i in lambda_test:\n",
    "        x_fista, f_fista = FISTA_deconv_ond_ortho(imconv,h,wave,step,lam,nbiter,x_init,fast=0)\n",
    "        if PSNR(x_dr,im2)>psnr:\n",
    "            psnr=PSNR(x_fb,imconv)\n",
    "            lambda_opti=i\n",
    "        print(\"lambda_test : \" + str(i))\n",
    "    return lambda_opti,psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_test,psnr = Test_param_opti()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fista, f_fista = FISTA_deconv_ond_ortho(imconv,h,wave,step,lambda_test,nbiter,x_init,fast=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(hv.Image(imconv, label = 'Image bruitée').opts(**options),hv.Image(x_fb, label = 'Image débruitée FISTA, meilleur paramètre').opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lambda_test,psnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests paramètres Douglas Rachford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(param.Parameterized):\n",
    "    gamma = param.Number(3,bounds=(0,3))\n",
    "    rho = param.Number(2,bounds=(0,10))\n",
    "    def view(self):\n",
    "        nbiter=500\n",
    "        wave='db2'\n",
    "        lam = 7\n",
    "        h=Gaussian2D(n1,blur[\"medium\"])\n",
    "        x_fb, f_fb= DouglasRachford_ortho(imconv,h,wave,lam,self.gamma,self.rho,nbiter,x_init)\n",
    "        pIrec = PSNR(x_fb,im2)\n",
    "        return pn.Row(hv.Image(x_fb,label=\"Im Douglas Rashford, PSNR = \" + str(round(pIrec,3))).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Test()\n",
    "pn.Row(test.param,test.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_test = np.linspace(0,5,6)\n",
    "gamma_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_param_opti():\n",
    "    lam = 7\n",
    "    psnr = 0.0\n",
    "    gamma_opti = 0\n",
    "    rho_opti = 0\n",
    "    gamma_test = np.linspace(0,5,6)\n",
    "    rho = [1,0.5,0.1,0.01,0.001,0.0001]\n",
    "    nbiter = 5000\n",
    "    for i in gamma_test:\n",
    "        for j in rho:\n",
    "            x_dr, f_dr= DouglasRachford_ortho(imconv,h,wave,lam,i,j,nbiter,x_init) \n",
    "            if PSNR(x_dr,im2)>psnr:\n",
    "                psnr=PSNR(x_dr,im2)\n",
    "                gamma_opti=i\n",
    "                rho_opti = j\n",
    "            print(\"gamma test : \" + str(i))\n",
    "    return gamma_opti,rho_opti,psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_rho_opti():\n",
    "    lam = 7\n",
    "    psnr = 0.0\n",
    "    rho_opti = 0\n",
    "    gamma = 1\n",
    "    rho = [2,1,0.5,0.1,0.01,0.001,0.0001,0.015,0.0015]\n",
    "    nbiter = 2000\n",
    "    \n",
    "    for j in rho:\n",
    "        x_dr, f_dr= DouglasRachford_ortho(imconv,h,wave,lam,gamma,j,nbiter,x_init) \n",
    "        if PSNR(x_dr,im2)>psnr:\n",
    "            psnr=PSNR(x_dr,im2)\n",
    "            rho_opti = j\n",
    "        print(\"rho test : \" + str(j))\n",
    "    return rho_opti,psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_opti_test,psnr = Test_rho_opti()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rho opti = \" + str(rho_opti_test))\n",
    "print(\"psnr = \" + str(psnr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_opti =1\n",
    "rho_opti =0.001\n",
    "nbiter = 2000\n",
    "x_dr, f_dr= DouglasRachford_ortho(imconv,h,wave,lam,gamma_opti,rho_opti_test,nbiter,x_init) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSNR(x_dr,im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(imconv).opts(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(x_dr).opts(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve(f_dr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici l'image défloutée grâce à l'algorithme Douglas Rashford"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste à présent une nouvelle image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test=np.array(Image.open(\"./image_deflou_carre_nb.jpg\")).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = dict(cmap='gray',xaxis=None,yaxis=None,width=450,height=450,toolbar=None)\n",
    "hv.Image(image_test[:,:,0]).opts(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1,n2=np.shape(image_test[:,:,0])\n",
    "h=Gaussian2D(n1,blur[\"medium\"])\n",
    "fh=np.fft.fft2(h)\n",
    "noise=np.random.randn(n1,n2)\n",
    "imconv=np.real(np.fft.ifft2(np.fft.fft2(image_test[:,:,0])*fh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On floute l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(imconv).opts(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = image_test[:,:,0]\n",
    "nbiter = 500\n",
    "x_dr, f_dr= DouglasRachford_ortho(imconv,h,wave,lam,gamma_opti,rho_opti_test,nbiter,x_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On défloute l'image à l'aide de Douglas , le résultat est proche de l'image de départ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(x_dr).opts(**options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste une autre image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test_2=np.array(Image.open(\"./test_test.jpg\")).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = dict(cmap='gray',xaxis=None,yaxis=None,width=450,height=450,toolbar=None)\n",
    "hv.Image(image_test_2[:,:,0]).opts(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1,n2=np.shape(image_test_2[:,:1680,0])\n",
    "h=Gaussian2D(n1,blur[\"medium\"])\n",
    "fh=np.fft.fft2(h)\n",
    "noise=np.random.randn(n1,n2)\n",
    "imconv=np.real(np.fft.ifft2(np.fft.fft2(image_test_2[:,:1680,0])*fh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On floute l'image de départ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(imconv).opts(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = image_test_2[:,:1680,0]\n",
    "nbiter = 500\n",
    "x_dr, f_dr= DouglasRachford_ortho(imconv,h,wave,lam,gamma_opti,rho_opti_test,nbiter,x_init) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On défloute l'image à l'aide de Douglas , le résultat est proche de l'image de départ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(x_dr).opts(**options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function estimates the best parameter $\\lambda$ for the function \\eqref{fonc_ond_ortho}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_paramater_fista3(imconv,im,nbiter,wave,h,x_init,lam_ref):\n",
    "    lam1=lam_ref/2\n",
    "    lam2=lam_ref*2\n",
    "    nbiter2=200\n",
    "    step=0.9\n",
    "    x_fista,f=FISTA_deconv_ond_ortho(imconv,h,wave,step,lam_ref,nbiter2,x_init,1)\n",
    "    x_fista1,f=FISTA_deconv_ond_ortho(imconv,h,wave,step,lam1,nbiter2,x_init,1)\n",
    "    x_fista2,f=FISTA_deconv_ond_ortho(imconv,h,wave,step,lam2,nbiter2,x_init,1)\n",
    "    p_ref=PSNR(x_fista,im)\n",
    "    p1=PSNR(x_fista1,im)\n",
    "    p2=PSNR(x_fista2,im)\n",
    "    while p1>p_ref:\n",
    "        lam1=lam1/2\n",
    "        x_fista1,f=FISTA_deconv_ond_ortho(imconv,h,wave,step,lam1,nbiter2,x_init,1)\n",
    "        p1=PSNR(x_fista1,im)\n",
    "    while p2>p_ref:\n",
    "        lam2=lam2*2\n",
    "        x_fista2,f=FISTA_deconv_ond_ortho(imconv,h,wave,step,lam1,nbiter2,x_init,1)\n",
    "        p2=PSNR(x_fista1,im)   \n",
    "    lam=np.sqrt(lam1*lam2)\n",
    "    #print(lam1,lam2,lam)\n",
    "    lamvar=np.sqrt(lam2/lam1)\n",
    "    for j in np.arange(6):\n",
    "        lam1=lam*lamvar\n",
    "        lam2=lam/lamvar\n",
    "        x_fista1,f=FISTA_deconv_ond_ortho(imconv,h,wave,step,lam1,nbiter2,x_init,1)\n",
    "        x_fista2,f=FISTA_deconv_ond_ortho(imconv,h,wave,step,lam2,nbiter2,x_init,1)\n",
    "        x_fista3,f=FISTA_deconv_ond_ortho(imconv,h,wave,step,lam,nbiter2,x_init,1)\n",
    "        p1=PSNR(x_fista1,im)\n",
    "        p2=PSNR(x_fista2,im)\n",
    "        p3=PSNR(x_fista3,im)\n",
    "        p=[p1,p2,p3]\n",
    "        lamb=[lam1,lam2,lam]\n",
    "        ind=np.argmax(p)\n",
    "        lam=lamb[ind]\n",
    "        lamvar=np.sqrt(lamvar)\n",
    "        p_ref=np.max(p)\n",
    "        #print(p_ref)\n",
    "        #print(lam)\n",
    "    return p_ref,lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=imagesRef[\"Lenna\"]\n",
    "#im=imagesRef[\"Canaletto\"]\n",
    "n1,n2=np.shape(im)\n",
    "std_blur=blur[\"medium\"]\n",
    "h=Gaussian2D(n1,std_blur)\n",
    "fh=np.fft.fft2(h)\n",
    "np.random.seed(seed=1)\n",
    "noise=np.random.randn(n1,n2)\n",
    "std_noise=22\n",
    "imconv=np.real(np.fft.ifft2(np.fft.fft2(im)*fh))+std_noise*noise\n",
    "wave='db2'\n",
    "nbiter=500\n",
    "x_init,p,lamop=wiener_op(imconv,fh,im,std_noise,std_blur)\n",
    "p3,lamop3=best_paramater_fista3(imconv,im,500,wave,h,x_init,2)\n",
    "print(lamop3)\n",
    "x_fista1,f=FISTA_deconv_ond_ortho(imconv,h,wave,0.9,lamop3,nbiter,x_init)\n",
    "#x_fista2,f2=FISTA_deconv_ond_ortho(imconv,h,wave,0.9,0.7,nbiter,x_init)\n",
    "print(PSNR(x_fista1,im))\n",
    "#print(PSNR(x_fista2,im))\n",
    "print(PSNR(x_init,im))\n",
    "pn.Row(hv.Image(x_fista1).opts(**options),hv.Image(x_init).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences2 = {'std_filter':blur.keys(),'std_noise':np.linspace(2,22,2)}\n",
    "dfexp2 = pd.DataFrame(list(itertools.product(*experiences2.values())),columns=experiences2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2PSNR_wave_FISTA(row):\n",
    "    np.random.seed(seed=1)\n",
    "    im=imagesRef[\"Lenna\"]\n",
    "    n1,n2=np.shape(im)\n",
    "    h=Gaussian2D(n1,blur[row.std_filter])\n",
    "    fh=np.fft.fft2(h)\n",
    "    noise=np.random.randn(n1,n2)\n",
    "    imconv=np.real(np.fft.ifft2(np.fft.fft2(im)*fh))+row.std_noise*noise\n",
    "    wave='db3'\n",
    "    nbiter=500\n",
    "    x_init,p,lamop=wiener_op(imconv,fh,im,row.std_noise,blur[row.std_filter])\n",
    "    #lamoracle=15*(row.std_noise**(1.8))/(blur[row.std_filter]*n1**2)\n",
    "    p3,lamop3=best_paramater_fista3(imconv,im,500,wave,h,x_init,2)\n",
    "    #p,maxp,lamop=best_paramater_fista(imconv,im,nbiter,wave,h,x_init,lamoracle)\n",
    "    return {'PSNR':p3,'Lambdaop':lamop3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowtest=  dfexp2.iloc[3]\n",
    "print(rowtest)\n",
    "result_test = row2PSNR_wave_FISTA(rowtest)\n",
    "print(result_test)\n",
    "result = dfexp2.apply(row2PSNR_wave_FISTA,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp2[['LambdaopwaveFISTA','PSNRwaveFISTA']] = pd.DataFrame.from_records(result.values)\n",
    "print(dfexp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = HoverTool()\n",
    "dfexp2.hvplot('std_noise','LambdaopwaveFISTA',kind='scatter',by=['std_filter'])\\\n",
    ".opts(width=600,tools = [h]).redim.range(LambdaopwaveFISTA=(0,20),std_noise=(0,23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2PSNR_wave_FISTA2(row):\n",
    "    np.random.seed(seed=1)\n",
    "    im=imagesRef[\"Lenna\"]\n",
    "    n1,n2=np.shape(im)\n",
    "    h=Gaussian2D(n1,blur[row.std_filter])\n",
    "    fh=np.fft.fft2(h)\n",
    "    noise=np.random.randn(n1,n2)\n",
    "    imconv=np.real(np.fft.ifft2(np.fft.fft2(im)*fh))+row.std_noise*noise\n",
    "    wave='db3'\n",
    "    lam=row.LambdaopwaveFISTA\n",
    "    nbiter=400\n",
    "    step=0.9\n",
    "    x_init,p,lamop=wiener_op(imconv,fh,im,row.std_noise,blur[row.std_filter])\n",
    "    x,f=FISTA_deconv_ond_ortho(imconv,h,wave,step,lam,nbiter,x_init,1)\n",
    "    p=PSNR(x,im)\n",
    "    return {'PSNR':p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowtest=  dfexp2.iloc[5]\n",
    "print(rowtest)\n",
    "result_test = row2PSNR_wave_FISTA2(rowtest)\n",
    "print(result_test)\n",
    "result = dfexp2.apply(row2PSNR_wave_FISTA2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp2[['PSNRwaveFISTAmaxiter']] = pd.DataFrame.from_records(result.values)\n",
    "print(dfexp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 Translation invariant wavelet representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deconvolution may be improved using a overcomplete wavelet representation (Translation Invariant Wavelet transform). \n",
    "To perform the deconvolution, we can solve the following optimization problem \n",
    "\\begin{equation}\\label{WaveTI}\n",
    "\\underset{x}{\\min}\\frac{1}{2}||h\\star x-y||_2^2+\\lambda||W_{TI}x||_1\n",
    "\\end{equation}\n",
    "where $W_TI$ is an orthogonal wavelet transform using Forward-Backward, FISTA or Douglas-Rachford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoftThresh_swt2(im,wave,thresh):\n",
    "    lvl=7\n",
    "    temp= pywt.swt2(im,wave,level=lvl,start_level=0,axes=(-2, -1),trim_approx=True, norm=True)\n",
    "    arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(temp)\n",
    "    wts=pywt.threshold(arr, thresh, mode='soft')\n",
    "    test=pywt.unravel_coeffs(wts, coeff_slices, coeff_shapes, output_format='swt2')\n",
    "    imrec=pywt.iswt2(test, wave,norm=True)\n",
    "    return imrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pywt.swt2(im,wave,level=7,start_level=0,axes=(-2, -1),trim_approx=True, norm=True)\n",
    "temp3=pywt.iswt2(test, 'db2', norm=True)\n",
    "imrec=SoftThresh_swt2(im,'db2',2.5)\n",
    "test= pywt.swt2(im,wave,level=7,start_level=0,axes=(-2, -1))\n",
    "temp3=pywt.iswt2(test, 'db2')\n",
    "imrec=SoftThresh_swt2(im,'db2',2.5)\n",
    "pn.Row(hv.Image(im, label='Image bruitée').opts(**options),hv.Image(imrec, label = 'Image Translation Invariante').opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=imagesRef[\"Lenna\"]\n",
    "n1,n2=np.shape(im)\n",
    "std_blur=blur[\"medium\"]\n",
    "h=Gaussian2D(n1,std_blur)\n",
    "fh=np.fft.fft2(h)\n",
    "np.random.seed(seed=1)\n",
    "noise=np.random.randn(n1,n2)\n",
    "std_noise=6\n",
    "imconv=np.real(np.fft.ifft2(np.fft.fft2(im)*fh))+std_noise*noise\n",
    "wave='db2'\n",
    "nbiter=500\n",
    "x_init,p,lamop=wiener_op(imconv,fh,im,std_noise,std_blur)\n",
    "p3,lamop3=best_paramater_fista3(imconv,im,500,wave,h,x_init,2)\n",
    "print(p3)\n",
    "x_fista1,f=FISTA_deconv_ond_ortho(imconv,h,wave,0.9,lamop3,nbiter,x_init,1)\n",
    "print(PSNR(x_fista1,im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(hv.Image(imconv).opts(**options),hv.Image(x_fista1).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gprox(z,x,b,fh,gamma):\n",
    "    no=np.linalg.norm(z-x,'fro')\n",
    "    res=gamma*foncconv(z,b,fh)+0.5*no**2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 : FB, FISTA for Translation invariant wavelets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FBDeconv(imconv,h,wave,step,lam,nbiter,x_init):\n",
    "    #Lmax=pywt.dwt_max_level(np.shape(imconv)[1],pywt.Wavelet(wave).dec_len)\n",
    "    fh=np.fft.fft2(h)\n",
    "    f=np.zeros(nbiter)\n",
    "    thresh=lam*step\n",
    "    lvl=7\n",
    "    alpha=0.01\n",
    "    x = x_init\n",
    "    for k in range(0,nbiter):\n",
    "        grad = gradfilter(x, imconv, fh)\n",
    "        x = SoftThresh_swt2(x-step*grad, wave, thresh)\n",
    "        temp= pywt.swt2(x,wave,level=lvl,start_level=0,axes=(-2, -1),trim_approx=True, norm=True)\n",
    "        arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(temp)\n",
    "        f[k] = foncconv(x, imconv, fh)+lam*sum(np.abs(arr))\n",
    "    x=np.clip(x,0,255)\n",
    "    return x,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam=5\n",
    "inst=time.time()\n",
    "x_fb,f_fb=FBDeconv(imconv,h,wave,0.08,lam,400,x_fista1)\n",
    "print(time.time()-inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('PSNR image initiale :',PSNR(x_init,im))\n",
    "print('PSNR image translation invariante FB :',PSNR(x_fb,im))\n",
    "pn.Row(hv.Image(imconv, label = 'Image bruitée').opts(**options),hv.Image(x_fb, label = 'Image débruitée translation invariante FB').opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve(f_fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FISTADeconv(imconv,h,wave,step,lam,nbiter,x_init,fast=0):\n",
    "    fh=np.fft.fft2(h)\n",
    "    f=np.zeros(nbiter)\n",
    "    thresh=lam*step\n",
    "    lvl=7\n",
    "    alpha=3\n",
    "    #Lmax=pywt.dwt_max_level(np.shape(imconv)[1],pywt.Wavelet(wave).dec_len)\n",
    "    x=x_init\n",
    "    x_old=x.copy()\n",
    "    for k in range(0,nbiter):\n",
    "        temp1 = x+(k/(k+alpha))*(x-x_old)\n",
    "        grad = gradfilter(temp1, imconv, fh)\n",
    "        x_old = x\n",
    "        x = SoftThresh_swt2(temp1-step*grad, wave, thresh)\n",
    "        if fast<1:\n",
    "            temp= pywt.swt2(x,wave,level=lvl,start_level=0,axes=(-2, -1),trim_approx=True, norm=True)\n",
    "            arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(temp)\n",
    "            f[k]=foncconv(x,imconv,fh)+lam*sum(np.abs(arr))\n",
    "    x=np.clip(x,0,255)\n",
    "    return x,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam=0.5\n",
    "inst=time.time()\n",
    "x_fista,f_fista=FISTADeconv(imconv,h,wave,0.08,lam,100,x_fista1,fast=0)\n",
    "print(time.time()-inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PSNR image initiale :',PSNR(x_init,im))\n",
    "print('PSNR image translation invariante FISTA :',PSNR(x_fista,im))\n",
    "pn.Row(hv.Image(imconv, label = 'Image bruitée').opts(**options),hv.Image(x_fista, label = 'Image débruitée translation invariante FISTA').opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve(f_fista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def DouglasRachford(imconv,h,wave,lam,gamma,rho,niter,x_init):\n",
    "#     fh=np.fft.fft2(h)\n",
    "#     init=imconv\n",
    "#     z=init.copy()\n",
    "#     y=init.copy()\n",
    "#     x=init.copy()\n",
    "    \n",
    "#     #thresh = lam *step\n",
    "#     Lmax=pywt.dwt_max_level(np.shape(imconv)[1],pywt.Wavelet(wave).dec_len)\n",
    "#     for k in range(0,niter):\n",
    "#         y = gradfilter(x,imconv,fh)\n",
    "#         z = SeuillageDouxOndelettes(2*y-x,wave,)  # x = SoftThresh_swt2(x-step*grad, wave, thresh)\n",
    "#         #z = gprox(2*y,x,imconv,fh,gamma)\n",
    "#         x = x + rho*(z-y)\n",
    "#         #temp = pywt.wavedecn(x,wave, mode='per', level=Lmax)\n",
    "#         #arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(temp)\n",
    "#         #f[k]=foncconv(x,imconv,fh)+lam*sum(np.abs(arr))\n",
    "#     x = np.clip(x,0,255)   \n",
    "#     return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lam=0.5\n",
    "# gamma=1\n",
    "# rho=0.9\n",
    "# inst=time.time()\n",
    "# x=DouglasRachford(imconv,h,'db2',lam,gamma,rho,10,x_fista1)\n",
    "# print(time.time()-inst)\n",
    "# print(PSNR(imconv,im))\n",
    "# print(PSNR(x,im))\n",
    "# pn.Row(hv.Image(imconv).opts(**options),hv.Image(x).opts(**options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 :Deconvolution with TV regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose now to perform the deconvolution minimizing the following function :\n",
    "\\begin{equation}\\label{TV}\n",
    "F(x)=\\frac{1}{2}||h\\star x-y||_2^2+\\lambda||\\nabla x||_1\n",
    "\\end{equation}\n",
    "where $\\nabla$ is the discrete gradient using two different Primal Dual algorithms. The first one is the Chambolle Pock Algorithm :\n",
    "\n",
    "https://hal.archives-ouvertes.fr/hal-00490826/document\n",
    "\n",
    "and the second one was proposed by Laurent Condat, see part 5 of \n",
    "\n",
    "https://www.gipsa-lab.grenoble-inp.fr/~laurent.condat/publis/Condat-optim-JOTA-2013.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientHor(x):\n",
    "    y=x-np.roll(x,1,axis=1)\n",
    "    y[:,0]=0\n",
    "    return y\n",
    "def GradientVer(x):\n",
    "    y=x-np.roll(x,1,axis=0)\n",
    "    y[0,:]=0\n",
    "    return y\n",
    "def DivHor(x):\n",
    "    N=len(x[0])\n",
    "    y=x-np.roll(x,-1,axis=1)\n",
    "    y[:,0]=-x[:,1]\n",
    "    y[:,N-1]=x[:,N-1]\n",
    "    return y\n",
    "def DivVer(x):\n",
    "    N=len(x)\n",
    "    y=x-np.roll(x,-1,axis=0)\n",
    "    y[0,:]=-x[1,:]\n",
    "    y[N-1,:]=x[N-1,:]\n",
    "    return y\n",
    "def Gradient(x):\n",
    "    y=[]\n",
    "    y.append(GradientHor(x))\n",
    "    y.append(GradientVer(x))\n",
    "    return y\n",
    "def Div(y):\n",
    "    x=DivHor(y[0])+DivVer(y[1])\n",
    "    return x\n",
    "def ProjGradBouleInf(g,l):\n",
    "    gh=g[0]\n",
    "    gv=g[1]\n",
    "    temp=g\n",
    "    p0=gh-(gh-l)*(gh>l)-(gh+l)*(gh<-l)\n",
    "    p1=gv-(gv-l)*(gv>l)-(gv+l)*(gv<-l)\n",
    "    temp[0]=p0\n",
    "    temp[1]=p1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chambolle-Pock Primal Dual "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 : Compute the Chambolle-Pock algorithm for the l_1 wavelet deconvolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChambollePockDeconv1(imconv,h,wave,tau,niter,init, gamma):\n",
    "    sigma=0.5/tau\n",
    "    fh=np.fft.fft2(h)\n",
    "    init=imconv\n",
    "    print(sigma)\n",
    "    xb=init.copy()\n",
    "    y=init.copy()\n",
    "    x=init.copy()\n",
    "    for k in range(0,niter):\n",
    "        Gradient = np.array([GradientHor(xb),GradientVer(xb)])\n",
    "        temp = y + sigma*Gradient\n",
    "        y = temp - sigma*SeuillageDouxOndelettes(1/sigma*temp, wave, 1/sigma)\n",
    "        x_old = x\n",
    "        x = proxfilter(x-tau*Div(y),imconv, fh, gamma)\n",
    "        xb= 2*x-x_old\n",
    "    return x    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter=100\n",
    "lam=1\n",
    "tau=0.01\n",
    "gamma = 1\n",
    "wave='db3'\n",
    "inst=time.time()\n",
    "x_cp=ChambollePockDeconv1(imconv,h,wave,tau,niter,imconv, gamma)\n",
    "print(time.time()-inst)\n",
    "print(PSNR(imconv,im))\n",
    "print(PSNR(x_cp,im))\n",
    "pn.Row(hv.Image(imconv).opts(**options),hv.Image(x_cp).opts(**options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 : Compute  the Chambolle-Pock algorithm for the TV deconvolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_h(x,Lambda):\n",
    "    return (x+Lambda)*(x<-Lambda)+(x-Lambda)*(x>Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChambollePockDeconvTV(imconv,h,lam,tau,niter,init,gamma): # ajout de gamma\n",
    "    sigma=0.05/tau\n",
    "    fh=np.fft.fft2(h)\n",
    "    x=init.copy()\n",
    "    xb=init.copy()\n",
    "    y=np.array([GradientHor(x),GradientVer(x)]) \n",
    "    init = imconv\n",
    "    for k in range(0,niter):\n",
    "        Gradient = np.array([GradientHor(xb),GradientVer(xb)])\n",
    "        temp = y + sigma*Gradient\n",
    "        y = temp - sigma*(prox_h((1/sigma)*temp,lam))\n",
    "        x_old = x\n",
    "        x = proxfilter(x-tau*Div(y),imconv,fh,gamma)\n",
    "        xb= 2*x-x_old\n",
    "    return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter=100\n",
    "lam=0.5\n",
    "tau=0.2\n",
    "gamma=0.2\n",
    "inst=time.time()\n",
    "x_cp=ChambollePockDeconvTV(imconv,h,lam,tau,niter,imconv,gamma)\n",
    "print(time.time()-inst)\n",
    "print(PSNR(imconv,im))\n",
    "print(PSNR(x_cp,im))\n",
    "pn.Row(hv.Image(imconv, label = 'Image bruitée').opts(**options),hv.Image(x_cp, label = 'Image débruitée').opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deconv_TV_CP(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Lenna\",objects=imagesRef.keys())\n",
    "    std_filter = param.ObjectSelector(default=\"medium\",objects=blur.keys())\n",
    "    std_noise= param.Number(10,bounds=(1,30))\n",
    "    loglam = param.Number(-0.5,bounds=(-5,4))\n",
    "    logtau = param.Number(-1.5,bounds=(-5,4))\n",
    "    loggamma = param.Number(-1.5,bounds=(-3,3))\n",
    "    nbiter = param.Integer(900,bounds=(1,3000))\n",
    "    def view(self):\n",
    "        imtemp=imagesRef[self.image]\n",
    "        np.random.seed(seed=1)\n",
    "        n1,n2=np.shape(imtemp)\n",
    "        noise=np.random.randn(n1,n2)\n",
    "        h=Gaussian2D(n1,blur[self.std_filter])\n",
    "        fh=np.fft.fft2(h)\n",
    "        lam=10**self.loglam\n",
    "        tau=10**self.logtau\n",
    "        gamma=10**self.loggamma\n",
    "        imconv=np.real(np.fft.ifft2(np.fft.fft2(imtemp)*fh))+self.std_noise*noise\n",
    "        x_cp=ChambollePockDeconvTV(imconv,h,lam,tau,self.nbiter,init=imconv,gamma=gamma)\n",
    "        p1=PSNR(imconv,imtemp)\n",
    "        p2=PSNR(x_cp,imtemp)\n",
    "        strp1=\"%2.2f\" % p1\n",
    "        strp2=\"%2.2f\" % p2\n",
    "        #strlam=\"%2.3f\"% lamop\n",
    "        #lames=3*self.std_noise/(blur[self.std_filter]*n1**2)\n",
    "        #strlames=\"%2.3f\"% lames\n",
    "        text1=hv.Text(0.5,0.3,'PSNR Blured '+strp1)\n",
    "        text2=hv.Text(0.5,0.7,'PSNR Deblured '+strp2)\n",
    "        #text3=hv.Text(nblambda/2,0.1*m+0.9*inf_lam,'Optimal lambda '+strlam)#+' et '+strlames)\n",
    "        fig=text1*text2\n",
    "        options_w = dict(cmap='gray',xaxis=None,yaxis=None,width=300,height=300,toolbar=None)\n",
    "        return pn.Column(pn.Row(hv.Image(imtemp).opts(**options_w)\\\n",
    "                      ,hv.Image(imconv).opts(**options_w)),\\\n",
    "                         pn.Row(hv.Image(x_cp).opts(**options_w),fig.opts(xaxis=None,yaxis=None,width=300,height=300,toolbar=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters : loglam = -0.40, logtau = -0.60 et loggamma = -1.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv_tv_cp= deconv_TV_CP()\n",
    "pn.Row(deconv_tv_cp.param,deconv_tv_cp.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condat Primal Dual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now solve the minization problem \\eqref{TV} using the Primal Dual by Condat.\n",
    "This algorithm has been designed to minimize of function of the form \n",
    "\\begin{equation}\n",
    "F(x)=f(x)+g(x)+\\sum_{m=1}^Mh_k(L_mx).\n",
    "\\end{equation}\n",
    "To solve \\eqref{TV} several choices are possible. Here to compare with the Chambolle Pock Primal Dual algorithm we will choose \n",
    "\n",
    "$f(x)=\\frac{1}{2}||h\\star x-y||^2_2$, $g=0$, $M=1$, $h_1(x)=||x||_1$ and $L_1x=\\nabla x$.\n",
    "\n",
    "The main difference with the previous approach is that this approach allows an explicit step on $f$.\n",
    "\n",
    "In this setting this algorithm is defined for any $\\rho\\in(0,1)$ and $\\tau$ and $\\sigma$ small enough by\n",
    "\\begin{equation}\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "\\tilde x_{k+1}=&x_k-\\tau \\nabla f(x_k)-\\tau div(u_k)\\\\\n",
    "x_{k+1}=&\\rho \\tilde x_{k+1}+(1-\\rho)x_k\\\\\n",
    "\\tilde u_{k+1}=&Proj_{\\mathcal{B}_{\\infty}(\\frac{1}{\\sigma})}(u_k+\\sigma\\nabla(2\\tilde x_{k+1}-x_k))\\\\\n",
    "u_{k+1}=&\\rho \\tilde u_{k+1}+(1-\\rho)u_k\n",
    "\\end{matrix}\n",
    "\\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 : Compute de Condat Primal dual algorithm for TV deconvolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CondatDeconvTV(imconv,h,lam,tau,sigma,rho,niter,init=imconv):\n",
    "    fh=np.fft.fft2(h)\n",
    "\n",
    "    x=init.copy()\n",
    "    xt=init.copy()   \n",
    "    u=Gradient(x)\n",
    "    ut=u.copy()\n",
    "    for k in range(0,niter):\n",
    "        grad= gradfilter(x, imconv, fh)\n",
    "        xt=x-tau*grad-tau*Div(u)\n",
    "        x_old=x\n",
    "        x=rho*xt+(1-rho)*x_old\n",
    "        ut=ProjGradBouleInf(u+sigma*np.array(Gradient(2.*xt-x)),1/sigma)\n",
    "        u_old=np.array(u)\n",
    "        u= rho*ut+(1-rho)*u_old\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam=0.05\n",
    "tau=0.01\n",
    "sigma=0.1\n",
    "rho=0.5\n",
    "niter=3000\n",
    "inst=time.time()\n",
    "x_cond=CondatDeconvTV(imconv,h,lam,tau,sigma,rho,niter,init=imconv)\n",
    "print(time.time()-inst)\n",
    "print(PSNR(imconv,im))\n",
    "print(PSNR(x_cond,im))\n",
    "pn.Row(hv.Image(imconv).opts(**options),hv.Image(x_cond).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deconv_TV_Conda(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Lenna\",objects=imagesRef.keys())\n",
    "    std_filter = param.ObjectSelector(default=\"medium\",objects=blur.keys())\n",
    "    std_noise= param.Number(6,bounds=(1,30))\n",
    "    loglam = param.Number(-1.2,bounds=(-5,4))\n",
    "    logtau = param.Number(-2,bounds=(-5,4))\n",
    "    logsigma = param.Number(-1,bounds=(-5,4))\n",
    "    rho = param.Number(0.5,bounds=(0,1))\n",
    "    nbiter = param.Integer(2000,bounds=(1,3000))\n",
    "    def view(self):\n",
    "        imtemp=imagesRef[self.image]\n",
    "        np.random.seed(seed=1)\n",
    "        n1,n2=np.shape(imtemp)\n",
    "        noise=np.random.randn(n1,n2)\n",
    "        h=Gaussian2D(n1,blur[self.std_filter])\n",
    "        fh=np.fft.fft2(h)\n",
    "        lam=10**self.loglam\n",
    "        tau=10**self.logtau\n",
    "        sigma=10**self.logsigma\n",
    "        rho=self.rho\n",
    "        imconv=np.real(np.fft.ifft2(np.fft.fft2(imtemp)*fh))+self.std_noise*noise\n",
    "        x_cond=CondatDeconvTV(imconv,h,lam,tau,sigma,rho,self.nbiter,imconv)\n",
    "        p1=PSNR(imconv,imtemp)\n",
    "        p2=PSNR(x_cond,imtemp)\n",
    "        strp1=\"%2.2f\" % p1\n",
    "        strp2=\"%2.2f\" % p2\n",
    "        #strlam=\"%2.3f\"% lamop\n",
    "        #lames=3*self.std_noise/(blur[self.std_filter]*n1**2)\n",
    "        #strlames=\"%2.3f\"% lames\n",
    "        text1=hv.Text(0.5,0.3,'PSNR Blured '+strp1)\n",
    "        text2=hv.Text(0.5,0.7,'PSNR Deblured '+strp2)\n",
    "        #text3=hv.Text(nblambda/2,0.1*m+0.9*inf_lam,'Optimal lambda '+strlam)#+' et '+strlames)\n",
    "        fig=text1*text2\n",
    "        options_w = dict(cmap='gray',xaxis=None,yaxis=None,width=300,height=300,toolbar=None)\n",
    "        return pn.Column(pn.Row(hv.Image(imtemp).opts(**options_w)\\\n",
    "                      ,hv.Image(imconv).opts(**options_w)),\\\n",
    "                         pn.Row(hv.Image(x_cond).opts(**options_w),fig.opts(xaxis=None,yaxis=None,width=300,height=300,toolbar=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv_tv_conda= deconv_TV_Conda()\n",
    "pn.Row(deconv_tv_conda.param,deconv_tv_conda.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few known results on explicit Gradient Descent and Forward-backward (FB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $F=f+g$ is a convex fucntion, sum of two convex functions, $f$ a differentiable function which gradient is $L-$Lipschitz and $g$ a convex function such that $prox_g$ is known, the Forward-Backward algorithm is defined by \n",
    "$$x_{n+1}=prox_{hg}(x_n-h\\nabla f(x_n))=Tx_n\\quad \\text{ with }T:=prox_{hg}\\circ (Id-h\\nabla f)$$\n",
    "One can show that the sequence $(F(x_n)-F(x^*))_{n\\in\\mathbb{N}}$ is non increasing and moreover \n",
    "$$F(x_n)-F(x^*)\\leqslant \\frac{2\\Vert x_0-x^*\\Vert^2}{hn}$$\n",
    "This decay rate $\\frac{1}{n}$ is optimal in the sens that it is impossible to get a bound decaying like $\\frac{1}{n^{\\delta}}$ with $\\delta>1$ for all convex fucntions. Nevertheless it can be proved that if $h<\\frac{1}{L}$ one actually has\n",
    "$$F(x_n)-F(x^*)=o\\left(\\frac{1}{n}\\right).$$  \n",
    "If the function $f$ is strongly convex the decay is geometrical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some rermarks on iteratives algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you use an iterative algorithm depending on one or more parameters, you must be careful to evaluate the results, the outputs of the algorithm. It is crucial to check some points :\n",
    "\n",
    "1) Check that the algorithm is close to converge... that is check that enough iterations have been done. This number of iterations may change depending on parameters and on the starting point $x_0$ chosen to build ythe sequence.\n",
    "\n",
    "To check this point, I Invite you to display the curve of the values $F(x_n)$ and to think twice about what you doing and what you see on the outputs. For example, if you are performing inpainting and if some black pixels left, or if the sequence $F(x_n)$ is still decaying quite fast, it means that it may be relevant to increse the number of iterations. More generally, observing the artefacts of defects on the output may give some clues of what can be done to improve the result. Moreover, have a look to the sequence $F(x_n)$ may indicate that less iterations could have been performed to get a similar output.\n",
    "\n",
    "2) Explore the possible values of paramters. It may occur that some values of parameters provide some relevant results and some don't. Before pretending that an algorithm is not efficient you must ensure that the parameters have been chosen wisely. These parameters can be the ones of the fucntion to minimize such as $\\lambda$ in \\eqref{Eq1} or the internal parameters of the algorithm such as the descent step for example. Making an Experiments Plan may be a good way to estimate the values of good parameters.\n",
    "\n",
    "One can observe that the value of $F(x)$ is not the only criterion to evaluate the output of an algorithm, actually for different values of $\\lambda$, the PSNR may be more relevant. We can't avoid thinking... \n",
    "\n",
    "3) When it it is possible choose a good starting point. Iterative algorithms build images (or signals) which converges to a minimiozer of the fucntion $F$. the choice of the staring point may be crucial. \n",
    "If we do not have any information, we can choose the constant image 0 or any relevant image, for example the masked image if we are performing inapainting or the noisy image if we are performing denoising. If for any problem a simple and quick method may provide a rough or innacurate output, it can be used as a starting point of the method. For the inpainting, we may start using a simple median filtering. The image is divided into small squares and the holes are filled up with the median value of the observed data.\n",
    "\n",
    "One can often distinguish two steps during the optimization of the function $F$, a first one to go from the starting point to a good image, a coarse approximation of the whished output and a second one from the coarse approximation to the whished output. It may be difficult to avoid the second step but the first one may be shortened using a good starting point.\n",
    "\n",
    "In many situations to compare several methods with various parameters or wavelet bases, it can be useful to compute the PSNR of each output on a benchmark to get a quite fair criterion for the comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceleration of Nesterov and FISTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yurii Nesterov has proposed in the 80's several methods to accelerate the explicit Gradient Descent. We will focus on one of these, the one that is described in the lesson. If you have a look to research paper be aware that the 2 words \"Nesterov accelerations\" may have several meanings... using interpolation or extrapolation, be specific to strongly convex functions or not. it may apply to the explicit Gradient Descent (GD) or to the Forward Backward algorithm. Moreover we will not use the original parameter of Nesterov or FISTA but the ones we proposed in 2014 with Antonin Chambolle to ensure the convergence of iterates and speed up the convergence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the acceleration of the GD proposed but Nesterov in 19!4 and adapted to FB under the name of FISTA by Beck and Teboulle in 2009 is easy the apply and without any additional computational cost.\n",
    "\n",
    "The idea is to apply the FB (or the GD for a single differntiable function) to a shifted point of $x_n$ with a step $h<\\frac{1}{L}$. \n",
    "Be careful this bound is more restrictive than the one for the classical GD :\n",
    "$$x_{n+1}=T(x_n+\\alpha_n(x_n-x_{n-1}))$$ \n",
    "where the sequence $\\alpha_n$ is chosen in a suitable way and $T$ is the FB operator. We say that FISTA is an inertial method because it uses an inertial term as a memory of the last descent direction.\n",
    "\n",
    "Let's give some key points of this method :\n",
    "1) The original choice of Nesterov for the sequence $\\alpha_n$ is the following :\n",
    "\\begin{equation}\n",
    "\\alpha_n=\\frac{t_n-1}{t_{n+1}}\\text{ avec }t_1=1\\text{ et }t_{n+1}=\\frac{1+\\sqrt{1+t_n^2}}{2}\n",
    "\\end{equation}\n",
    "2) For this choice we have \n",
    "$$F(x_n)-F(x^*)\\leqslant \\frac{2\\Vert x_0-x^*\\Vert^2}{hn^2}$$\n",
    "3) We can take the more simple choice $\\alpha_n=\\frac{n-1}{n+a-1}$ with $a>3$ (and that's what you will implement) and in this cas we have \n",
    "$$F(x_n)-F(x^*)\\leqslant \\frac{(a-1)^2\\Vert x_0-x^*\\Vert^2}{2h(n+a)^2}$$ and moreover \n",
    "$F(x_n)-F(x^*)=o\\left(\\frac{1}{n^2}\\right)$ and the sequence $(x_n)_{n\\geqslant 1}$ converges. \n",
    "It can be noticed, there are no inertia in the first step ($\\alpha_1=0$) and thus $x_1=T(x_0)$. \n",
    "The inertia appears for the computation of $x_2$. The original choice of Nesterov is very close to the choice $\\alpha=3$.\n",
    "\n",
    "4) In the case of a composite fucntion ($F$ is a sum of a diffrentiable fucntion $f$ and a possibly non smooth fucntion $g$), this inertial algorithm is called FISTA (Fast Iterative Soft Shrinkage Thresholding Algorithm) because when $g$ is the $\\ell_1$ norm, the proximal operator is a soft thresholding but the name FISTA is the name of this algorithm even if $g$ is not an $\\ell_1$ norm.\n",
    "\n",
    "5) Unlike FB, the sequence $(F(x_n)-F(x^*))_{n\\geqslant 1}$ given by FISTA is not necessarily non increasing. The previous bounds on FB or FISTA are only ... bounds... but does not describe the real decay rate.\n",
    "In practical cases you should see that FISTA is often faster than FB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Several definitions of the Total Variation (TV) Norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It exists several definitions of the TV norm . The one we are using here is the anisotropic TV norm, it also exists an isotropic one :\n",
    "\n",
    "https://en.wikipedia.org/wiki/Total_variation_denoising\n",
    "\n",
    "The use of the isotropic TV norm leads to artefacts that are more homogenious in all directions. \n",
    "The difference between the two approaches are particularly visible on the corners and the sides of objects.\n",
    "\n",
    "To deal with an isotropic norm, you have to change the norme in \\eqref{Primal}, and thus the definition of the \n",
    "$\\ell_\\infty$ ball in the dual problem is a bit different.\n",
    "\n",
    "You must be aware that this difference exists and be clear in your mind about the norms you are using. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising of colored images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible de denoise colored images, applying the previous algorithms on each chromatic chanel, but it is also possible to work directly on the colored image and define a global 3D TV norm on the three chanels, summing over the whole image, the norm of a gradient with ... 6 components. The goal of this approach is to avoid incoherence between the 3 chromatic chanels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take away message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implement a FB algorithm, nesterov accelerations are often efficient and it is always useful to test and even to test several choices of $a$. beginning with $a=3$. One can notive that, at least theoretically, the sequence   \n",
    "generated $(F(x_n)-F(x^*))_{n\\geqslant 1}$ generated by FB as a geometrical decay when $F$ is strongly convex, which is not the case for the studied Nesterov scheme. But it exists some accelerations that are dedicated to this specific situation. In practical cases, for a reasonnable number of iterations, these Nesterov accelerations are really competitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "38efaa045fcc2680aaeae51f7ac851acc4f32df019d3afeeab3c12114d76b9ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
